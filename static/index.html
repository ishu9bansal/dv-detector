<!DOCTYPE html>
<html>
<head>
    <title>Real-Time Emotion Detector</title>
    <style>
        body { font-family: Arial; text-align: center; padding: 50px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; min-height: 100vh; }
        .container { background: rgba(255,255,255,0.1); padding: 40px; border-radius: 20px; backdrop-filter: blur(10px); max-width: 600px; margin: 0 auto; }
        #emotion { font-size: 150px; margin: 30px; animation: pulse 2s infinite; }
        @keyframes pulse { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.1); } }
        #label { font-size: 60px; font-weight: bold; margin: 20px; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); }
        #confidence { font-size: 35px; margin: 10px; }
        #audioLevel { font-size: 20px; margin: 10px; color: #00ff87; }
        .timestamp-box { background: rgba(255,255,255,0.15); padding: 15px; border-radius: 10px; margin: 20px auto; max-width: 500px; }
        .timestamp { font-size: 16px; margin: 5px; color: #ffd700; font-family: monospace; }
        .lag { font-size: 18px; margin: 10px; color: #ff6b6b; font-weight: bold; }
        .emotions-breakdown { background: rgba(255,255,255,0.15); padding: 20px; border-radius: 10px; margin: 20px auto; max-width: 500px; }
        .emotions-breakdown h4 { margin: 0 0 15px 0; font-size: 20px; color: #ffd700; }
        .emotion-bar { margin: 8px 0; text-align: left; }
        .emotion-label { font-size: 14px; margin-bottom: 3px; display: flex; justify-content: space-between; }
        .emotion-progress { background: rgba(255,255,255,0.2); border-radius: 10px; height: 20px; overflow: hidden; }
        .emotion-fill { height: 100%; background: linear-gradient(90deg, #f093fb 0%, #f5576c 100%); transition: width 0.3s; }
        button { padding: 20px 50px; font-size: 24px; cursor: pointer; border: none; border-radius: 50px; background: linear-gradient(45deg, #f093fb 0%, #f5576c 100%); color: white; font-weight: bold; transition: transform 0.2s; margin: 20px; }
        button:hover { transform: scale(1.05); }
        #status { font-size: 20px; margin: 20px; padding: 15px; background: rgba(255,255,255,0.2); border-radius: 10px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé≠ Real-Time Emotion Detector</h1>
        <h3>97.46% Accuracy - Pipeline Method</h3>
        <div id="emotion">üé≠</div>
        <div id="label">READY</div>
        <div id="confidence">0%</div>
        <div id="audioLevel">Audio Level: 0%</div>
        <div class="timestamp-box">
            <div class="timestamp" id="inputTime">Input: --</div>
            <div class="timestamp" id="processedTime">Processed: --</div>
            <div class="lag" id="lagTime">Lag: -- ms</div>
        </div>
        <div class="emotions-breakdown">
            <h4>üìä All Emotions</h4>
            <div id="emotionsBreakdown"></div>
        </div>
        <button onclick="toggleRecording()">START</button>
        <p id="status">Click START</p>
    </div>

    <script>
        let ws, audioContext, processor, source, isRecording = false;
        const emojiMap = {'angry': 'üò†', 'disgust': 'ü§¢', 'fear': 'üò®', 'happy': 'üòä', 'neutral': 'üòê', 'sad': 'üò¢', 'surprise': 'üò≤'};

        async function toggleRecording() {
            if (!isRecording) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({audio: true});
                    ws = new WebSocket('ws://localhost:8000/ws');
                    
                    ws.onopen = () => { document.getElementById('status').innerText = 'üé§ LISTENING!'; };
                    
                    ws.onmessage = (e) => {
                        const data = JSON.parse(e.data);
                        const receivedTimestamp = Date.now();
                        
                        // Show readiness reason when not ready
                        if (data.ready === false && data.notReadyReason) {
                            let reason = data.notReadyReason;
                            if (reason === 'insufficient_buffer') {
                                document.getElementById('status').innerText = '‚è≥ Buffering audio...';
                            } else if (reason === 'silence') {
                                document.getElementById('status').innerText = 'ü§´ Too quiet ‚Äî speak up!';
                            } else {
                                document.getElementById('status').innerText = '‚ö†Ô∏è ' + reason;
                            }
                            if (typeof data.level === 'number') {
                                document.getElementById('audioLevel').innerText = 'Level: ' + data.level + '%';
                            }
                            return;
                        }

                        if (data.silence) {
                            document.getElementById('status').innerText = '‚ö†Ô∏è SILENCE - Speak!';
                            document.getElementById('audioLevel').innerText = 'Level: ' + data.level + '%';
                        } else {
                            document.getElementById('emotion').innerText = emojiMap[data.emotion] || 'üé≠';
                            document.getElementById('label').innerText = data.emotion.toUpperCase();
                            document.getElementById('confidence').innerText = (data.confidence * 100).toFixed(1) + '%';
                            document.getElementById('audioLevel').innerText = 'Level: ' + data.level + '%';
                            document.getElementById('status').innerText = '‚úÖ ' + data.emotion;
                            
                            document.getElementById('processedTime').innerText = 'Processed: ' + new Date(receivedTimestamp).toLocaleTimeString() + '.' + (receivedTimestamp % 1000).toString().padStart(3, '0');
                            
                            if (data.inputTimestamp) {
                                const lag = receivedTimestamp - data.inputTimestamp;
                                document.getElementById('lagTime').innerText = 'Lag: ' + lag + ' ms';
                            }
                            
                            if (data.allEmotions) {
                                const emotionOrder = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'];
                                const emotionMap = {};
                                data.allEmotions.forEach(em => { emotionMap[em.label] = em.score; });
                                
                                let html = '';
                                emotionOrder.forEach(emotionName => {
                                    const score = emotionMap[emotionName] || 0;
                                    const isPrimary = emotionName === data.emotion;
                                    const emoji = emojiMap[emotionName] || 'üé≠';
                                    const percent = (score * 100).toFixed(1);
                                    html += `
                                        <div class="emotion-bar">
                                            <div class="emotion-label">
                                                <span>${emoji} ${emotionName.toUpperCase()}${isPrimary ? ' ‚≠ê' : ''}</span>
                                                <span>${percent}%</span>
                                            </div>
                                            <div class="emotion-progress">
                                                <div class="emotion-fill" style="width: ${percent}%"></div>
                                            </div>
                                        </div>
                                    `;
                                });
                                document.getElementById('emotionsBreakdown').innerHTML = html;
                            }
                        }
                    };

                    audioContext = new AudioContext({sampleRate: 16000});
                    source = audioContext.createMediaStreamSource(stream);
                    processor = audioContext.createScriptProcessor(16384, 1, 1);
                    
                    processor.onaudioprocess = (e) => {
                        if (ws.readyState === WebSocket.OPEN) {
                            const inputTimestamp = Date.now();
                            ws.send(JSON.stringify({
                                audio: Array.from(e.inputBuffer.getChannelData(0)),
                                timestamp: inputTimestamp
                            }));
                            document.getElementById('inputTime').innerText = 'Input: ' + new Date(inputTimestamp).toLocaleTimeString() + '.' + (inputTimestamp % 1000).toString().padStart(3, '0');
                        }
                    };
                    
                    source.connect(processor);
                    processor.connect(audioContext.destination);
                    
                    isRecording = true;
                    document.querySelector('button').innerText = 'STOP';
                    document.querySelector('button').style.background = 'linear-gradient(45deg, #ff6b6b 0%, #ee5a6f 100%)';
                } catch(err) { alert('Mic denied!'); }
            } else {
                if (processor) processor.disconnect();
                if (source) source.disconnect();
                if (audioContext) audioContext.close();
                if (ws) ws.close();
                isRecording = false;
                document.querySelector('button').innerText = 'START';
                document.querySelector('button').style.background = 'linear-gradient(45deg, #f093fb 0%, #f5576c 100%)';
            }
        }
    </script>
</body>
</html>
